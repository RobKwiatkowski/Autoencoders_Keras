{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Reading Libraries\n",
    "\n",
    "__author__ = \"Robert Kwiatkowski\"\n",
    "__license__ = \"GPL\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importing keras components\n",
    "from keras.layers import Conv2D, UpSampling2D, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.initializers import glorot_normal\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # module for splitting data into train and test sets\n",
    "from skimage.color import rgb2lab  # module for converting RGB color model to LAB\n",
    "from tqdm import tqdm  # module for displaying a progress bar\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # library for visualisations\n",
    "import tensorflow as tf  # library with NN core components\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "from tensorflow.python.client import device_lib  # module for checking available local devices\n",
    "\n",
    "print(tf.__version__)\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Reading Data\n",
    "path_imgs = r\"\\Inputs\"\n",
    "\n",
    "img_size=(256,256)\n",
    "\n",
    "#Normalize images - divide by 255\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#Resize images, if needed\n",
    "train = train_datagen.flow_from_directory(path_imgs, \n",
    "                                          target_size=img_size, \n",
    "                                          batch_size=340, \n",
    "                                          class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Convert from RGB to Lab\n",
    "\n",
    "X =[]\n",
    "Y =[]\n",
    "for img in tqdm(train[0]):\n",
    "  try:\n",
    "      lab = rgb2lab(img)\n",
    "      X.append(lab[:,:,0]) \n",
    "      Y.append(lab[:,:,1:] / 128)\n",
    "  except:\n",
    "     print('error')\n",
    "     \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X = X.reshape(X.shape+(1,)) #dimensions to be the same for X and Y\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "samples = len(X)\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Construction phase\n",
    "np.random.seed(124)\n",
    "leaky_alpha = 0.1\n",
    "\n",
    "#Encoder\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=glorot_normal(), strides=2, input_shape=(256, 256, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=glorot_normal(), strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal(), strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=glorot_normal(), strides=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(1024, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "#Decoder\n",
    "\n",
    "model.add(Conv2D(512, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(8, (3,3), padding='same', kernel_initializer=glorot_normal()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=leaky_alpha))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same', kernel_initializer=glorot_normal()))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Execution phase\n",
    "batch = 28\n",
    "epochs = 400\n",
    "path_model = r\"models\\beach.model\"\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   min_delta=0.0001, \n",
    "                   patience=75, \n",
    "                   verbose=0, \n",
    "                   mode='auto', \n",
    "                   baseline=None, \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "checkpt = ModelCheckpoint(path_model, \n",
    "                          monitor='val_loss',\n",
    "                          verbose=0,\n",
    "                          save_best_only=True,\n",
    "                          mode='auto')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch, \n",
    "                    callbacks=[es, checkpt])\n",
    "model.save(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot training history 1\n",
    "plt.plot(history.history['loss'][20:], label='train')\n",
    "plt.plot(history.history['val_loss'][20:], label='test')\n",
    "plt.title(\"Lossess\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot training history 2\n",
    "plt.plot(history.history['accuracy'][10:], label='train')\n",
    "plt.plot(history.history['val_accuracy'][10:], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_color = []\n",
    "img1 = img_to_array(load_img(r'validation\\inputs\\black.jpg'))\n",
    "img1 = resize(img1 ,(256,256))\n",
    "img1_color.append(img1)\n",
    "img1_color = np.array(img1_color, dtype=float)\n",
    "img1_color = rgb2lab(1.0/255*img1_color)[:,:,:,0]\n",
    "img1_color = img1_color.reshape(img1_color.shape+(1,))\n",
    "\n",
    "output1 = model.predict(img1_color)\n",
    "output1 = output1*128\n",
    "result = np.zeros((256, 256, 3))\n",
    "result[:,:,0] = img1_color[0][:,:,0]\n",
    "result[:,:,1:] = output1[0]\n",
    "imsave(r\"validation\\results\\results.jpg\", lab2rgb(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
